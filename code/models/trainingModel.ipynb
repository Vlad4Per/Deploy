{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 84792,
     "databundleVersionId": 9524838,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30761,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Practical machine learning and deep learning. Lab 2\n# Tools and Processes for Machine Learning and Data Analysis\n\n## [Competition](https://www.kaggle.com/t/936f7286a02b4161b70e9037553ef01d)\n\n### Goal\n\nIn Lab 2, you have two tasks: 1) recap the training flow of a neural network and 2) use a traking tool to control this flow. \n\n### Submission\nYour are asked to implement a neural network to classify if there is a person with blond hairs on a photo and generate `submission.csv` for the test set.",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Frameworks we're using in this lab\n",
    "\n",
    "#### PyTorch\n",
    "   PyTorch is an open-source machine learning library primarily developed by Meta's (компания признана экстремистской организацией на территории Российской Федерации) AI Research lab . It is widely used for deep learning tasks.\n",
    "\n",
    "#### Tensorboard\n",
    "   TensorBoard is a visualization tool provided by TensorFlow for monitoring and visualizing the training process and model performance during machine learning experiments.\n",
    "\n",
    "\n",
    "#### ClearML\n",
    "   ClearML is an open-source machine learning platform designed to automate and streamline the end-to-end machine learning workflow, including data management, model training, and deployment."
   ]
  },
  {
   "cell_type": "code",
   "source": "!pip install tensorboard",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:52:03.434285Z",
     "iopub.execute_input": "2024-09-12T22:52:03.434767Z",
     "iopub.status.idle": "2024-09-12T22:52:03.439915Z",
     "shell.execute_reply.started": "2024-09-12T22:52:03.434726Z",
     "shell.execute_reply": "2024-09-12T22:52:03.438561Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:45:51.150260Z",
     "start_time": "2024-09-29T13:45:49.019429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\users\\pv010\\miniconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\pv010\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from tensorboard) (1.66.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\pv010\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from tensorboard) (5.28.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from tensorboard) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from tensorboard) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": "import warnings\nwarnings.filterwarnings(\"ignore\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:52:03.442655Z",
     "iopub.execute_input": "2024-09-12T22:52:03.443692Z",
     "iopub.status.idle": "2024-09-12T22:52:03.458976Z",
     "shell.execute_reply.started": "2024-09-12T22:52:03.443645Z",
     "shell.execute_reply": "2024-09-12T22:52:03.457699Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:45:51.169484Z",
     "start_time": "2024-09-29T13:45:51.166268Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T13:45:52.692688Z",
     "start_time": "2024-09-29T13:45:51.180718Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install torch ",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\pv010\\miniconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from torch) (68.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T13:45:54.169450Z",
     "start_time": "2024-09-29T13:45:52.780175Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install matplotlib",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\pv010\\miniconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pv010\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T13:45:55.667579Z",
     "start_time": "2024-09-29T13:45:54.259427Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install torchvision",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\pv010\\miniconda3\\lib\\site-packages (0.19.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.4.1 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from torchvision) (2.4.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from torch==2.4.1->torchvision) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from torch==2.4.1->torchvision) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from torch==2.4.1->torchvision) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from torch==2.4.1->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from torch==2.4.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from torch==2.4.1->torchvision) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from torch==2.4.1->torchvision) (68.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from jinja2->torch==2.4.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pv010\\miniconda3\\lib\\site-packages (from sympy->torch==2.4.1->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Data set\n\nData set, a part of [CelebA](https://www.kaggle.com/datasets/jessicali9530/celeba-dataset/data), contain about 11,000 cropped images of faces. Your task is to detect people with blond hairs or do binary classification (blondy\\not blondy) for each image.\n\nThere are several small challenges you're going to face with the dataset. First, the images are much bigger than in regular learning sets—178 by 218 pixels in RGB scale. Second, the CelebA dataset is quite well- labelled, and each image has lots of metadata about face features. Usually, they are used to train generative or face recognition models. We intentionally left all of these features, which are redundant for solving this task.\n\nPlease do not train a classifier on other data than given (including other parts of CelebA).\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 1.1 Data preprocessing",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# necessary imports\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom tqdm.notebook import tqdm\n\nfrom torch.utils.tensorboard import SummaryWriter\n\nimport torchvision.transforms as transforms\nfrom torchvision.io import read_image",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2024-09-12T22:52:03.460416Z",
     "iopub.execute_input": "2024-09-12T22:52:03.460769Z",
     "iopub.status.idle": "2024-09-12T22:52:03.472832Z",
     "shell.execute_reply.started": "2024-09-12T22:52:03.460734Z",
     "shell.execute_reply": "2024-09-12T22:52:03.471690Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:45:59.679446Z",
     "start_time": "2024-09-29T13:45:55.745323Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": "from torchvision.transforms import v2\n\ndef load_img(fname):\n    \"\"\"\n    Load an image from file, do transformation (including possible augmentation) and return it as torch.tensor\n\n    :param fname: path to jpg image\n    \"\"\"\n    img = read_image(fname)\n    x = img / 255.\n    \n    # Write your code here\n    transform = transforms.Compose(\n    [\n        transforms.Resize((224, 224)),                # Resize image to 224x224 (or the size of your model input)\n        transforms.RandomHorizontalFlip(p=0.5),       # Random horizontal flip with 50% probability\n        transforms.ColorJitter(brightness=0.2,        # Randomly change brightness, contrast, and saturation\n                               contrast=0.2, \n                               saturation=0.2),\n        transforms.RandomRotation(degrees=15),        # Randomly rotate the image by up to 15 degrees\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                             std=[0.229, 0.224, 0.225]),\n        v2.ToDtype(torch.float32, scale=True),  # Convert to float and scale\n        # Keep color augmentations minimal as we're detecting hair color:\n        ]\n    )\n    \n    return transform(x)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:52:03.474469Z",
     "iopub.execute_input": "2024-09-12T22:52:03.474841Z",
     "iopub.status.idle": "2024-09-12T22:52:03.491139Z",
     "shell.execute_reply.started": "2024-09-12T22:52:03.474795Z",
     "shell.execute_reply": "2024-09-12T22:52:03.490064Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:45:59.719333Z",
     "start_time": "2024-09-29T13:45:59.686735Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "img_path = \"C:/Users/pv010/OneDrive/Рабочий стол/Homework/PMDL/Assignment 1/DeployedModel/code/datasets/archive\"\n",
    "# img_path = \"C:/Users/pv010/OneDrive/Рабочий стол/Homework/PMDL/Drafts/hw2/archive\"\n",
    "# Image attributes\n",
    "train_features = pd.read_csv(f\"{img_path}/train.csv\")\n",
    "\n",
    "# Load and transform images \n",
    "images = torch.stack([load_img(f\"{img_path}/img_align_celeba/train/{item['image_id']}\") for _, item in  train_features.iterrows()])\n",
    "\n",
    "# Write your code here\n",
    "# Select label(s) from train_features\n",
    "labels = train_features.get('Blond_Hair')\n",
    "# Leave values that only 1 or 0 and convert to float just for simplicity\n",
    "labels.replace(-1, 0, inplace=True)\n",
    "labels = torch.from_numpy(labels.to_numpy()).float()\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:52:03.493677Z",
     "iopub.execute_input": "2024-09-12T22:52:03.494068Z",
     "iopub.status.idle": "2024-09-12T22:54:19.124245Z",
     "shell.execute_reply.started": "2024-09-12T22:52:03.494029Z",
     "shell.execute_reply": "2024-09-12T22:54:19.122976Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:47:59.773509Z",
     "start_time": "2024-09-29T13:45:59.726013Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": "## 1.2 Visualization",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\n\n\ndef plot_images(images, captions=[], rows=2, columns=5, title=\"\", **kwargs):\n    \"\"\"\n    Plots images with captions\n\n    :param images: list of images to plot\n    :param captions: captions of images:\n    :param rows: number of rows in figure\n    :param columns: number of columns:\n    :param title: super title of figure\n    \"\"\"\n    fig = plt.figure(figsize=(6, 3))\n    for i, img in enumerate(images):\n        fig.add_subplot(rows, columns, i + 1)\n        plt.imshow(img, **kwargs)\n        if i < len(captions):\n            plt.title(captions[i])\n        plt.axis(\"off\")\n    fig.suptitle(title)\n    plt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:54:19.134918Z",
     "iopub.execute_input": "2024-09-12T22:54:19.136059Z",
     "iopub.status.idle": "2024-09-12T22:54:19.148664Z",
     "shell.execute_reply.started": "2024-09-12T22:54:19.136004Z",
     "shell.execute_reply": "2024-09-12T22:54:19.147288Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:48:01.241439Z",
     "start_time": "2024-09-29T13:48:00.151951Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": "## 1.3 Data loaders creation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from torch.utils.data import TensorDataset, DataLoader\n\nprocessed_dataset = TensorDataset(images, labels)\n\n# Write your code here\n# Set proportion and split dataset into train and validation parts\nproportion = 0.9\n\ntrain_dataset, val_dataset = torch.utils.data.random_split(\n    processed_dataset,\n   [(int(len(images) * proportion)), len(images) - int(len(images) * proportion)],\n)\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:54:19.624878Z",
     "iopub.execute_input": "2024-09-12T22:54:19.625288Z",
     "iopub.status.idle": "2024-09-12T22:54:19.632823Z",
     "shell.execute_reply.started": "2024-09-12T22:54:19.625244Z",
     "shell.execute_reply": "2024-09-12T22:54:19.631485Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:48:01.276905Z",
     "start_time": "2024-09-29T13:48:01.263418Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": "# Create Dataloaders for training and validation \n# Dataloader is iterable object over dataset\nbatch_size = 64\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:54:19.634680Z",
     "iopub.execute_input": "2024-09-12T22:54:19.635046Z",
     "iopub.status.idle": "2024-09-12T22:54:20.031783Z",
     "shell.execute_reply.started": "2024-09-12T22:54:19.635009Z",
     "shell.execute_reply": "2024-09-12T22:54:20.030633Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:48:01.307693Z",
     "start_time": "2024-09-29T13:48:01.298317Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Training\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 2.1 Defining a model\n\nWe will implement CNN\n\n> if you want higher score implement any suitable model you know and like\n\nCheck Pytorch [documentation](https://pytorch.org/docs/stable/nn.html): layers, loss functions, etc",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNNClassificationModel(nn.Module):\n",
    "    \"\"\"\n",
    "    MLP (multi-layer perceptron) based classification model for MNIST\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNNClassificationModel, self).__init__()\n",
    "\n",
    "        # Add fully connected layers to nn.Sequential to create MLP\n",
    "        # First layer should take 28x28 vector\n",
    "        # last layer should return vector of size num_classes\n",
    "        # do not forget to add activation function between layers\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.Conv2d(3, 4, kernel_size=(3, 3), stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(4),\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(4, 8, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(8),\n",
    "        )\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(95048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(16, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:58:12.262937Z",
     "iopub.execute_input": "2024-09-12T22:58:12.263487Z",
     "iopub.status.idle": "2024-09-12T22:58:12.274631Z",
     "shell.execute_reply.started": "2024-09-12T22:58:12.263441Z",
     "shell.execute_reply": "2024-09-12T22:58:12.273197Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:48:01.334887Z",
     "start_time": "2024-09-29T13:48:01.327067Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": "## 2.2 Defining training & validation loops\n\nHere is the sample function for training procedure. \nWe save the checkpoints with best accuracy score. For the inference you need to load it to the model.\n\n> You can add early stopping if you want for better results",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def train(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    writer=None,\n",
    "    epochs=1,\n",
    "    device=\"cpu\",\n",
    "    ckpt_path=\"../models/best.pt\",\n",
    "):\n",
    "    # best score for checkpointing\n",
    "    best = 0.0\n",
    "    \n",
    "    # iterating over epochs\n",
    "    for epoch in range(epochs):\n",
    "        # training loop description\n",
    "        train_loop = tqdm(\n",
    "            enumerate(train_loader, 0), total=len(train_loader), desc=f\"Epoch {epoch}\"\n",
    "        )\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        # iterate over dataset \n",
    "        for data in train_loop:\n",
    "            # Write your code here\n",
    "            # Move data to a device, do forward pass and loss calculation, do backward pass and run optimizer\n",
    "            id, (inputs, labels) = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.type(torch.int64)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_loop.set_postfix({\"loss\": loss.item()})\n",
    "        # write loss to tensorboard\n",
    "        if writer:\n",
    "            writer.add_scalar(\"Loss/train\", train_loss / len(train_loader), epoch)\n",
    "        \n",
    "        # Validation\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()  # evaluation mode\n",
    "            val_loop = tqdm(enumerate(val_loader, 0), total=len(val_loader), desc=\"Val\")\n",
    "            for data in val_loop:\n",
    "                id, (inputs, labels) = data\n",
    "                # Write your code here\n",
    "                # Get predictions and compare them with labels\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                labels = labels.type(torch.int64)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                for i, j in zip(predicted,labels):\n",
    "                    if i == j: correct += 1\n",
    "                    \n",
    "                val_loop.set_postfix({\"acc\": correct / total})\n",
    "\n",
    "            if correct / total > best:\n",
    "                torch.save(model.state_dict(), ckpt_path)\n",
    "                best = correct / total\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:54:20.046643Z",
     "iopub.execute_input": "2024-09-12T22:54:20.047140Z",
     "iopub.status.idle": "2024-09-12T22:54:20.060442Z",
     "shell.execute_reply.started": "2024-09-12T22:54:20.047086Z",
     "shell.execute_reply": "2024-09-12T22:54:20.059190Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-29T14:07:38.521434Z",
     "start_time": "2024-09-29T14:07:38.513595Z"
    }
   },
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": "## 2.3 Combining everything together",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "from model import CNNClassificationModel\n",
    "# Write your code here\n",
    "# Pick optimizer from torch.optim and loss function loss_fn from torch.nn that suits best the model\n",
    "# SummaryWriter is used by tensorboard and could be set None\n",
    "model = CNNClassificationModel()\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    optimizer=optim.Adam(model.parameters(), lr=0.001),\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device='cpu',\n",
    "    writer=SummaryWriter(),\n",
    "    epochs=7\n",
    ")\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:58:17.164571Z",
     "iopub.execute_input": "2024-09-12T22:58:17.165023Z",
     "iopub.status.idle": "2024-09-12T23:07:28.870641Z",
     "shell.execute_reply.started": "2024-09-12T22:58:17.164981Z",
     "shell.execute_reply": "2024-09-12T23:07:28.869202Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-29T14:09:24.542678Z",
     "start_time": "2024-09-29T14:07:43.678515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 0:   0%|          | 0/166 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b401a6bbee0148608982cdf9cf94fbf4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Val:   0%|          | 0/19 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1520a9b9f16240b3b609d15915b93b2a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 1:   0%|          | 0/166 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1ce2e022ecb43989d89ca2accf15889"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 7\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# Write your code here\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Pick optimizer from torch.optim and loss function loss_fn from torch.nn that suits best the model\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# SummaryWriter is used by tensorboard and could be set None\u001B[39;00m\n\u001B[0;32m      5\u001B[0m model \u001B[38;5;241m=\u001B[39m CNNClassificationModel()\n\u001B[1;32m----> 7\u001B[0m train(\n\u001B[0;32m      8\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m      9\u001B[0m     optimizer\u001B[38;5;241m=\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m),\n\u001B[0;32m     10\u001B[0m     loss_fn\u001B[38;5;241m=\u001B[39mnn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss(),\n\u001B[0;32m     11\u001B[0m     train_loader\u001B[38;5;241m=\u001B[39mtrain_loader,\n\u001B[0;32m     12\u001B[0m     val_loader\u001B[38;5;241m=\u001B[39mval_loader,\n\u001B[0;32m     13\u001B[0m     device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     14\u001B[0m     writer\u001B[38;5;241m=\u001B[39mSummaryWriter(),\n\u001B[0;32m     15\u001B[0m     epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m7\u001B[39m\n\u001B[0;32m     16\u001B[0m )\n",
      "Cell \u001B[1;32mIn[33], line 35\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, optimizer, loss_fn, train_loader, val_loader, writer, epochs, device, ckpt_path)\u001B[0m\n\u001B[0;32m     33\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(outputs, labels)\n\u001B[0;32m     34\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m---> 35\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     37\u001B[0m train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m     38\u001B[0m train_loop\u001B[38;5;241m.\u001B[39mset_postfix({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m\"\u001B[39m: loss\u001B[38;5;241m.\u001B[39mitem()})\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:484\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    479\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    480\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    481\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    482\u001B[0m             )\n\u001B[1;32m--> 484\u001B[0m out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    485\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    487\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:89\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     87\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     88\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[1;32m---> 89\u001B[0m     ret \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     91\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\optim\\adam.py:226\u001B[0m, in \u001B[0;36mAdam.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    214\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    216\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[0;32m    217\u001B[0m         group,\n\u001B[0;32m    218\u001B[0m         params_with_grad,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    223\u001B[0m         state_steps,\n\u001B[0;32m    224\u001B[0m     )\n\u001B[1;32m--> 226\u001B[0m     adam(\n\u001B[0;32m    227\u001B[0m         params_with_grad,\n\u001B[0;32m    228\u001B[0m         grads,\n\u001B[0;32m    229\u001B[0m         exp_avgs,\n\u001B[0;32m    230\u001B[0m         exp_avg_sqs,\n\u001B[0;32m    231\u001B[0m         max_exp_avg_sqs,\n\u001B[0;32m    232\u001B[0m         state_steps,\n\u001B[0;32m    233\u001B[0m         amsgrad\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamsgrad\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    234\u001B[0m         has_complex\u001B[38;5;241m=\u001B[39mhas_complex,\n\u001B[0;32m    235\u001B[0m         beta1\u001B[38;5;241m=\u001B[39mbeta1,\n\u001B[0;32m    236\u001B[0m         beta2\u001B[38;5;241m=\u001B[39mbeta2,\n\u001B[0;32m    237\u001B[0m         lr\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    238\u001B[0m         weight_decay\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight_decay\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    239\u001B[0m         eps\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meps\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    240\u001B[0m         maximize\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    241\u001B[0m         foreach\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mforeach\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    242\u001B[0m         capturable\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcapturable\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    243\u001B[0m         differentiable\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    244\u001B[0m         fused\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfused\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    245\u001B[0m         grad_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrad_scale\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m    246\u001B[0m         found_inf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m    247\u001B[0m     )\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:161\u001B[0m, in \u001B[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    159\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m disabled_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    160\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 161\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\optim\\adam.py:766\u001B[0m, in \u001B[0;36madam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[0;32m    763\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    764\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[1;32m--> 766\u001B[0m func(\n\u001B[0;32m    767\u001B[0m     params,\n\u001B[0;32m    768\u001B[0m     grads,\n\u001B[0;32m    769\u001B[0m     exp_avgs,\n\u001B[0;32m    770\u001B[0m     exp_avg_sqs,\n\u001B[0;32m    771\u001B[0m     max_exp_avg_sqs,\n\u001B[0;32m    772\u001B[0m     state_steps,\n\u001B[0;32m    773\u001B[0m     amsgrad\u001B[38;5;241m=\u001B[39mamsgrad,\n\u001B[0;32m    774\u001B[0m     has_complex\u001B[38;5;241m=\u001B[39mhas_complex,\n\u001B[0;32m    775\u001B[0m     beta1\u001B[38;5;241m=\u001B[39mbeta1,\n\u001B[0;32m    776\u001B[0m     beta2\u001B[38;5;241m=\u001B[39mbeta2,\n\u001B[0;32m    777\u001B[0m     lr\u001B[38;5;241m=\u001B[39mlr,\n\u001B[0;32m    778\u001B[0m     weight_decay\u001B[38;5;241m=\u001B[39mweight_decay,\n\u001B[0;32m    779\u001B[0m     eps\u001B[38;5;241m=\u001B[39meps,\n\u001B[0;32m    780\u001B[0m     maximize\u001B[38;5;241m=\u001B[39mmaximize,\n\u001B[0;32m    781\u001B[0m     capturable\u001B[38;5;241m=\u001B[39mcapturable,\n\u001B[0;32m    782\u001B[0m     differentiable\u001B[38;5;241m=\u001B[39mdifferentiable,\n\u001B[0;32m    783\u001B[0m     grad_scale\u001B[38;5;241m=\u001B[39mgrad_scale,\n\u001B[0;32m    784\u001B[0m     found_inf\u001B[38;5;241m=\u001B[39mfound_inf,\n\u001B[0;32m    785\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\optim\\adam.py:433\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[0;32m    430\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    431\u001B[0m         denom \u001B[38;5;241m=\u001B[39m (exp_avg_sq\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[1;32m--> 433\u001B[0m     param\u001B[38;5;241m.\u001B[39maddcdiv_(exp_avg, denom, value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39mstep_size)\n\u001B[0;32m    435\u001B[0m \u001B[38;5;66;03m# Lastly, switch back to complex view\u001B[39;00m\n\u001B[0;32m    436\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m amsgrad \u001B[38;5;129;01mand\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mis_complex(params[i]):\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": "## 2.4 Inference\nHere you need to perform inference of trained model on test data. \n\nLoad the best checkpoint from training to the model and run inference",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# load best checkpoint to model\n",
    "from pathlib import Path\n",
    "model = CNNClassificationModel()\n",
    "Path(\"../models/best.pt\").rename(\"C:/Users/pv010/OneDrive/Рабочий стол/Homework/PMDL/Assignment 1/DeployedModel/models/best.pt\")\n",
    "ckpt = torch.load(\"C:/Users/pv010/OneDrive/Рабочий стол/Homework/PMDL/Assignment 1/DeployedModel/models/best.pt\")\n",
    "model.load_state_dict(ckpt)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T23:09:50.760106Z",
     "iopub.execute_input": "2024-09-12T23:09:50.760621Z",
     "iopub.status.idle": "2024-09-12T23:09:51.279987Z",
     "shell.execute_reply.started": "2024-09-12T23:09:50.760577Z",
     "shell.execute_reply": "2024-09-12T23:09:51.278837Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-29T14:15:51.843589Z",
     "start_time": "2024-09-29T14:15:51.370531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def predict(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Run model inference on test data\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # evaluation mode\n",
    "        test_loop = tqdm(enumerate(test_loader, 0), total=len(test_loader), desc=\"Test\")\n",
    "\n",
    "        for inputs in test_loop:\n",
    "            # Write your code here\n",
    "            # Similar to validation part in training cell\n",
    "            id, pred = inputs\n",
    "            pred = pred.to(device)\n",
    "            _, predicted = torch.max(model(pred).data, 1)\n",
    "\n",
    "            # Extend overall predictions by prediction for a batch\n",
    "            predictions.extend([i.item() for i in predicted])\n",
    "        return predictions\n"
   ]
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T23:10:41.451022Z",
     "iopub.execute_input": "2024-09-12T23:10:41.451486Z",
     "iopub.status.idle": "2024-09-12T23:10:50.886004Z",
     "shell.execute_reply.started": "2024-09-12T23:10:41.451446Z",
     "shell.execute_reply": "2024-09-12T23:10:50.884850Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-09-29T13:58:42.768580Z",
     "start_time": "2024-09-29T13:58:32.480756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# process test data and run inference on it\n",
    "test_features = pd.read_csv(f\"{img_path}/test.csv\")\n",
    "images = torch.stack([load_img(f\"{img_path}/img_align_celeba/test/{item['image_id']}\") for _, item in  test_features.iterrows()])\n",
    "\n",
    "test_loader = DataLoader(images, batch_size=batch_size, shuffle=False)\n",
    "predictions = predict(model, test_loader, device='cpu')\n",
    "\n",
    "# generate the submission file\n",
    "submission_df = pd.DataFrame(columns=['ID', 'Blond_Hair'])\n",
    "submission_df['ID'] = test_features.index\n",
    "submission_df['Blond_Hair'] = predictions\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "submission_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Test:   0%|          | 0/16 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ee254ac02e84fa9865af6eae2d79d29"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "   ID  Blond_Hair\n",
       "0   0           1\n",
       "1   1           0\n",
       "2   2           0\n",
       "3   3           0\n",
       "4   4           0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Blond_Hair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  }
 ]
}
